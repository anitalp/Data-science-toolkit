MULTIPLE CORRESPONDANCE ANALYSIS
=================================

####Importante:

El **análisis de corresopndencia** es un análisis multivariante aplicado a métodos de interdependencia ( ninguna variable depende de otra).
Hay varios tipos : el análisis de correspondencia simple (con dos variables) y el múltiple (con más de dos variables).

La diferencia con el análisis factorial (por ejemplo PCA) se halla en que el análisis de correspondencia (CA), se aplica a variables cualitativas, mientras que el análisis factorial (PCA), se aplica a variables cuantitativas.

Se calcula usando diferencias cuadradas y distancias euclídeas.

El estudio suele hacerse sobre 2 dimensiones.

######NOTA: 
Omitir valores atípicos (outliers).
For further details sobre la interpretación de los gráficos mirar apuntes.


```{r, cache=TRUE}

########## MULTIPLE CORRESPONDANCE ANALYSIS

#  CATEGORICAL DATA

## References: http://gastonsanchez.com/blog/how-to/2012/10/13/MCA-in-R.html

# 
# 
# Today is the turn to talk about five different options of doing Multiple Correspondence Analysis in R 
# (don't confuse it with Correspondence Analysis).
# Put in very simple terms, Multiple Correspondence Analysis (MCA) is to qualitative data, 
# as Principal Component Analysis (PCA) is to quantitative data. 
# Well, maybe I'm oversimplifying a little bit because MCA has some special features that make 
# it mathematically different from PCA, but they both share a lot of things in common from a data 
# analysis standpoint.
# As with PCA and Correspondence Analysis, MCA is just another tool in our kit of multivariate methods 
# that allows us to analyze the systematic patterns of variations with categorical data. Keep in mind 
# that MCA applies to tables in which the observations are described by a set of qualitative (i.e. categorical)
# variables. This means that in R you must have your table in the form of a data frame with factors 
# (observations in the rows, qualitative variables in the columns).
# 
#### MCA in R
# 
# In R, there are several functions from different packages that allow us to apply Multiple 
# Correspondence Analysis. In this post I'll show you 5 different ways to perform MCA using the 
# following functions (with their corresponding packages in parentheses):
# -MCA() (FactoMineR)
# -mca() (MASS)
# -dudi.acm() (ade4)
# -mjca() (ca)
# -homals() (homals)
# No matter what function you decide to use for MCA, the typical results should consist of a set of 
# eigenvalues, a table with the row coordinates, and a table with the column coordinates.
# Compared to the eigenvalues obtained from a PCA or a CA, the eigenvalues in a MCA can be much more 
# smaller. This is important to know because if you just consider the eigenvalues, you might be tempted
# to conclude that MCA sucks. Which is absolutely false.
# Personally, I think that the real meat and potatoes of MCA relies in its dimension reduction properties
# that let us visualize our data, among other things. Besides the eigenvalues, the row coordinates 
# provide information about the structure of the rows in the analyzed table. In turn, the column 
# coordinates provide information about the structure of the analyzed variables and their corresponding
# categories.
# 
# 
# ###### The Data

# We'll use the dataset tea that comes in the R package "FactoMineR" . 
# It's a data frame (of factors) containing the answers of a questionnaire on tea consumption 
# for 300 individuals. Although the data contains 36 columns (i.e. variables), for demonstration
# purposes I will only consider the following columns:
#   
# What kind of tea do you drink (black, green, flavored)
# How do you drink it (alone, w/milk, w/lemon, other)
# What kind of presentation do you buy (tea bags, loose tea, both)
# Do you add sugar (yes, no)
# Where do you buy it (supermarket, shops, both)
# Do you always drink tea (always, not always)


# load packages
require(FactoMineR)
require(ggplot2)

# load data tea
data(tea)

# select these columns
newtea = tea[, c("Tea", "How", "how", "sugar", "where", "always")]

# take a peek
head(newtea)

# number of categories per variable
cats = apply(newtea, 2, function(x) nlevels(as.factor(x)))

cats

#Option 1: using MCA()
# #My preferred function to do multiple correspondence analysis is the MCA() function that 
# comes in the fabulous package "FactoMineR" by Francois Husson, Julie Josse, Sebastien Le, 
# and Jeremy Mazet. If you have seen my other posts you'll know that this is one of favorite
# packages and I strongly recommend other users to seriously take a look at it. It provides 
# the most complete list of results with different calculations for interpretation and diagnosis.

# apply MCA
mca1 = MCA(newtea, graph = FALSE)

# list of results
mca1
# 
# **Results of the Multiple Correspondence Analysis (MCA)**
#   The analysis was performed on 300 individuals, described by 6 variables
# *The results are available in the following objects:
#   
#   name              description                       
# 1  "$eig"            "eigenvalues"                     
# 2  "$var"            "results for the variables"       
# 3  "$var$coord"      "coord. of the categories"        
# 4  "$var$cos2"       "cos2 for the categories"         
# 5  "$var$contrib"    "contributions of the categories" 
# 6  "$var$v.test"     "v-test for the categories"       
# 7  "$ind"            "results for the individuals"     
# 8  "$ind$coord"      "coord. for the individuals"      
# 9  "$ind$cos2"       "cos2 for the individuals"        
# 10 "$ind$contrib"    "contributions of the individuals"
# 11 "$call"           "intermediate results"            
# 12 "$call$marge.col" "weights of columns"              
# 13 "$call$marge.li"  "weights of rows" 

mca1$eig
# 
# eigenvalue percentage of variance cumulative percentage of variance
# dim 1  0.27976178              15.259733                          15.25973
# dim 2  0.25774772              14.058967                          29.31870
# dim 3  0.22013794              12.007524                          41.32622
# dim 4  0.18792961              10.250706                          51.57693
# dim 5  0.16876495               9.205361                          60.78229
# dim 6  0.16368666               8.928363                          69.71065
# dim 7  0.15288834               8.339364                          78.05002
# dim 8  0.13838682               7.548372                          85.59839
# dim 9  0.11569167               6.310455                          91.90885
# dim 10 0.08612637               4.697802                          96.60665
# dim 11 0.06221147               3.393353                         100.00000



# data frame with variable coordinates
mca1_vars_df = data.frame(mca1$var$coord, Variable = rep(names(cats), cats))

# data frame with observation coordinates
mca1_obs_df = data.frame(mca1$ind$coord)

# plot of variable categories
ggplot(data=mca1_vars_df, 
       aes(x = Dim.1, y = Dim.2, label = rownames(mca1_vars_df))) +
  geom_hline(yintercept = 0, colour = "gray70") +
  geom_vline(xintercept = 0, colour = "gray70") +
  geom_text(aes(colour=Variable)) +
  ggtitle("MCA plot of variables using R package FactoMineR")


#In order to have a more interesting representation, 
#we could superimpose a graphic display of both the observations and the categories. 
#Moreover, since some individuals will be overlapped, we can add some density curves with
#geom_density2d() to see those zones that are highly concentrated:

  # MCA plot of observations and categories
  ggplot(data = mca1_obs_df, aes(x = Dim.1, y = Dim.2)) +
  geom_hline(yintercept = 0, colour = "gray70") +
  geom_vline(xintercept = 0, colour = "gray70") +
  geom_point(colour = "gray50", alpha = 0.7) +
  geom_density2d(colour = "gray80") +
  geom_text(data = mca1_vars_df, 
            aes(x = Dim.1, y = Dim.2, 
                label = rownames(mca1_vars_df), colour = Variable)) +
  ggtitle("MCA plot of variables using R package FactoMineR") +
  scale_colour_discrete(name = "Variable")


#### CONCLUSI?N

#Los usuarios que no beben te siempre cuando lo hacen es con leche y az?car, adem?s suele 
#ser Earl Grey. Sin embargo, los que lo beben siempre suelen beberlo negro y sin az?car.
#Los que lo compran en tiendas shop, lo comprarn sin empaquetar.

```
